---
title: "DSS Comptuing Bootcamp"
author: "Mine Çetinkaya-Rundel and Colin Rundel"
date: "Aug 19 and Aug 21, 2015"
output:
  ioslides_presentation:
    highlight: pygments
    widescreen: yes
---

## Materials

- Slides at http://bit.ly/comp_boot_slides
- All source code at http://bit.ly/comp_boot_repo
- *Very* useful resources from RStudio:
    + [R Markdown cheat sheet](https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf)
    + [R Markdown reference guide](https://www.rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf)
    + [Data wrangling with dplyr and tidyr cheat sheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf)
    + [Data visualization with ggplot2 cheat sheet](https://www.rstudio.com/wp-content/uploads/2015/05/ggplot2-cheatsheet.pdf)



# Reproducibility: who cares?

## Science retracts gay marriage paper without agreement of lead author LaCour

- In May 2015 Science retracted a study of how canvassers can sway 
people's opinions about gay marriage published just 5 months ago.

- Science Editor-in-Chief Marcia McNutt: Original survey data not made 
available for independent reproduction of results. + Survey incentives 
misrepresented. + Sponsorship statement false.

- Two Berkeley grad students who attempted to replicate the study quickly 
discovered that the data must have been faked.

- Methods we'll discuss today can't prevent this, but they can make it 
easier to discover issues.

Source: http://news.sciencemag.org/policy/2015/05/science-retracts-gay-marriage-paper-without-lead-author-s-consent


## Seizure study retracted after authors realize data got "terribly mixed"

From the authors of **Low Dose Lidocaine for Refractory Seizures in 
Preterm Neonates**:

*"The article has been retracted at the request of the authors. After 
carefully re-examining the data presented in the article, they identified 
that data of two different hospitals got terribly mixed. The published 
results cannot be reproduced in accordance with scientific and clinical 
correctness."*

Source: http://retractionwatch.com/2013/02/01/seizure-study-retracted-after-authors-realize-data-got-terribly-mixed/


## Bad spreadsheet merge kills depression paper, quick fix resurrects it

- The authors informed the journal that the merge of lab results and other 
survey data used in the paper resulted in an error regarding the 
identification codes. Results of the analyses were based on the data set 
in which this error occurred. Further analyses established the results 
reported in this manuscript and interpretation of the data are not correct.

- **Original conclusion:** Lower levels of CSF IL-6 were associated with 
current depression and with future depression [...].

- **Revised conclusion:** Higher levels of CSF IL-6 and IL-8 were 
associated with current depression [...].

Source: http://retractionwatch.com/2014/07/01/bad-spreadsheet-merge-kills-depression-paper-quick-fix-resurrects-it/



# Reproducibility: why should we care?

## Two-pronged approach

<div class="columns-2">
\#1 
Convince researchers to adopt a reproducible research workflow

<br><br>

\#2
Train new researchers who don’t have any other workflow

![two prongs](img/two-pronged-fork.jpg)

</div>

## Reproducible data analysis

- Scriptability $\rightarrow$ R

- Literate programming $\rightarrow$ R Markdown

- Version control $\rightarrow$ Git / GitHub

# Departmental computing resources

## Departmental computing resources

- Graduate student computers are shared departmental resources
    + You'll be assigned a desktop to which you have priority, but it may 
    be used by others as well (and you can use others' later if needed -- 
    more on this later)

- Dedicated servers: 
    + `gort`: Undergrad
    + `saxon`: MS
    + `smith`: PhD
    
- Home directories are all network shared and backed up

- DSS computing inventory: https://stat.duke.edu/resources/computing/inventory.html

## Remote connections

- You will be doing much of your work on remote linux systems, primarily 
you will be interacting with these machines through a remote terminal and 
a shell. Using a shell gives you more power to do more tasks more 
efficiently with your computer.

- OSX / Unix / Linux - these tools should already be installed and you 
should be able to access your shell through the Terminal application (name 
may vary slightly depending on your OS).

- Windows - there are several ways to install bash or a bash-like shell, 
the preferred method is to install the `git for windows` package: 
https://git-for-windows.github.io/.



# On to ssh

## Secure shell (ssh)

- A secure tool for connecting and interacting with remote systems
- Uses public key encryption
- Run a single command or work interactively
- Lots of other neat tricks (proxy, port forwarding, many more)

## Connecting to saxon / smith

- PhD: `smith`, MS: `saxon`
- Everyone should have a visitor account of the stats servers now
- Try to connect to make sure everything is working...

```bash
$ ssh cr173@saxon.stat.duke.edu
The authenticity of host 'saxon.stat.duke.edu (152.3.7.55)' can't be established
.
RSA key fingerprint is 74:30:5a:d0:cd:a8:d2:6f:a6:e9:c6:80:bb:eb:b4:ba.
Are you sure you want to continue connecting (yes/no)?yes
cr173@saxon.stat.duke.edu's password:
[cr173@saxon ~]$
```

## Working remotely {.smaller}

You should now be able to run commands remotely on `saxon`. We can 
interactively run commands on the remote system. Try `lscpu` to see the 
cpu configuration on server.

```bash
[cr173@saxon ~]$ lscpu
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                24
On-line CPU(s) list:   0-23
Thread(s) per core:    2
Core(s) per socket:    6
Socket(s):             2
NUMA node(s):          2
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 62
Stepping:              4
CPU MHz:               1200.000
BogoMIPS:              4199.43
Virtualization:        VT-x
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              15360K
NUMA node0 CPU(s):     0-5,12-17
NUMA node1 CPU(s):     6-11,18-23
```

## Finishing up

Once you are done on the server you can exit by:

- Running `exit`
- Ctrl-D
- Wait long enough (connection will time out)

## Secure copy (scp)

Uses ssh to copy a file between systems

```bash
$ ls -la
total 0
drwxr-xr-x   2 rundel  staff    68 Aug 28 21:51 .
drwxr-xr-x  98 rundel  staff  3332 Aug 28 21:51 ..
$ touch file
$ ls -la
total 0
drwxr-xr-x   3 rundel  staff   102 Aug 28 21:52 .
drwxr-xr-x  98 rundel  staff  3332 Aug 28 21:51 ..
-rw-r--r--   1 rundel  staff     0 Aug 28 21:52 file
```

##

Now we can upload the empty file

```bash
$ ssh cr173@saxon.stat.duke.edu "ls -la file*"
ls: No match.
$ scp file cr173@saxon.stat.duke.edu:~/
file                                                   100%    0     0.0KB/s   00:00
$ ssh cr173@saxon.stat.duke.edu "ls -la file*"
-rw-r--r--+ 1 cr173 visitor 0 Aug 28 21:55 file
```

Similarly if we change the file on the server, we can then download it 
locally as well:

```bash
$ ssh cr173@saxon.stat.duke.edu "echo Hello! > file"
$ ssh cr173@saxon.stat.duke.edu cat file
Hello!
$ scp cr173@saxon.stat.duke.edu:~/file ./
file                                                   100%    7     0.0KB/s   00:00 
$ cat file
Hello!
```

# Version control

## Why version control? {.smaller}

<div class="centered" style="margin-top: -1em;">
![PhD Comics](img/phd_comics_vc.gif)
</div>

## Why version control?

- Simple formal system for tracking all changes to a project

- Time machine for your projects
    + Track blame and/or praise
    + Remove the fear of breaking things

- Learning curve is steep, but when you need it you *REALLY* need it

<br/>
<br/>

<div class="centering">
<blockquote>
Your closest collaborator is you six months ago, but you don’t reply to emails.
</blockquote>
<cite>-- Paul Wilson, UW-Madison</cite>
</div>

## Why git?

- Distributed
    + Work online or offline
    + Collaborate with large groups

- Popular and Successful
    + Active development
    + Shiny new tools and ecosystems
    + Fast

- Tracks any type of file

- Branching
    + Smarter merges
    
# Git live demo

## Git live demo

- Create a GitHub account

- Create a repository

- Clone a repository

- Working with a local and remote repository

- Resolving merge conflicts

- Best practices for version control

## Learn more

https://try.github.io

# Scripting and literate programming 

## Donald Knuth "Literate Programming (1983)"

"Let us change our traditional attitude to the construction of programs: 
Instead of imagining that our main task is to instruct a *computer* what 
to do, let us concentrate rather on explaining to *human beings* what we 
want a computer to do."

"The practitioner of literate programming [...] strives for a program that 
is comprehensible because its concepts have been introduced in an order 
that is best for human understanding, using a mixture of formal and 
informal methods that reinforce each other."

- These ideas have been around for years!
- and tools for putting them to practice have also been around
- but they have never been as accessible as the current tools


## Reproducibility checklist

- Are the tables and figures reproducible from the code and data?
- Does the code actually do what you think it does?
- In addition to what was done, is it clear *why* it was done? (e.g., how 
were parameter settings chosen?)
- Can the code be used for other data?
- Can you extend the code to do other things?

## Ambitious goal + many other concerns 

We need an environment where

- data, analysis, and results are tightly connected, or better yet, 
inseparable

- reproducibility is built in
    + the original data remains untouched
    + all data manipulations and analyses are inherently documented

- documentation is human readable and syntax is minimal

## Toolkit

<center>
![toolkit](img/toolkit.png)
</center>

## Accessing RStudio

- Go to http://smith.stat.duke.edu:8787/

- Log in with your Net ID and password

## Create a project

RStudio projects make it straightforward to divide your work into multiple 
contexts, each with their own working directory, workspace, history, and 
source documents.

- File -> New Project -> Existing Directory

- Browse for the directory of the project you cloned from GitHub earlier

## What is in the project?

- `.gitignore`: Files you don't want tracked in the repo

- `README.md`: By default contains the description of the repo

## What is markdown?

- Markdown is a lightweight markup language for creating HTML (or XHTML) 
documents.

- Markup languages are designed to produce documents from human readable 
text (and annotations).

- Some of you may be familiar with LaTeX. This is another (less human 
friendly) markup language for creating pdf documents.

- Why I love Markdown:
    + Easy to learn and use.
    + Focus on **content**, rather than **coding** and debugging 
    **errors**.
    + Once you have the basics down, you can get fancy and add HTML,
    JavaScript, and CSS.
    
## Why should I use Markdown?

If you have an annoying process for authoring for the web ...

or

If you avoid authoring for the web, because you're not sure how ...

**start writing in Markdown**!

## Edit and commit a file

- Make changes to `README.md` and save
    + Learn more Markdown syntax at 
    https://help.github.com/articles/markdown-basics/

- In the *Git* pane, check *Staged* for the file you changes, and click 
*Commit*
    + a pop-up window will appear

- Review the diff and add an **informative** commit message and click 
*Commit*

- Close the pop-up window, in the *Git* pane, click *Push*
    + this will prompt you to enter your GitHub login info
    
- Go to your repo on GitHub and confirm that changes have been made

## Create and push a markdown file

- File -> New File -> R Markdown

- Compile and view HTML output

- Add `.html` to the `.gitignore`, save, and commit

- Commit the generated report
    + Check *Staged* for the Rmd file and commit
    
- Push

## R packages {.smaller}

- Packages are the fundamental units of reproducible R code. They include 
reusable R functions, the documentation that describes how to use them, 
and sample data.

- In the following exercises we'll use `curl`, `dplyr`, and `ggplot2` 
packages.

- Install these packages bu running the following in the *Console*

```{r eval = FALSE}
install.packages("curl")
install.packages("dplyr")
install.packages("ggplot2")
```

- Note that you will also need to load them in your markdown file (R code 
goes in chunks)

```{r message=FALSE}
library(curl)
library(dplyr)
library(ggplot2)
```

## It's your lucky day, you got some data!

Load the data using the `read.csv` function

```{r}
gap <- read.csv(curl("http://bit.ly/gap_data"))
```

## 

**Ex 1: (a) How many observations are in this dataset?
(b) Visualize the relationship between GDP and life expectancy for 
countries in Europe in 1952 using a scatter plot.**

```{r, fig.height=3.5, fig.width=7}
eu_52 <- gap %>%
  filter(continent == "Europe", year == 1952)
ggplot(data = eu_52, aes(x = gdpPercap, y = lifeExp)) +
  geom_point()                                          
```

## Ex 1 done?

commit

## 

**Ex 2: Add year 1967 in another color.**

1. Create a subset of `gap` for Europe in 1952 **and 1967** and call it 
`eu_5267`. Some hints to get you started:

    + Update your subset to also include 1952: `year %in% c(1952, 1967)`.
    + Update the name of the resulting data frame to `eu_5267`
    
2. Create the plot. Some more hints:

    + Update the name of the data frame being referred to in the `ggplot` 
    function.
    + Add another aesthetic to the plot for plotting data from th two 
    years in difference colors: `color = factor(year)`. Note that this 
    says the color of the points should be determined by the year, and 
    that we should consider year as a categorical (factor) variable 
    (either 1952 or 1967).

##

```{r, fig.height=3.75, fig.width=7}
eu_5267 <- gap %>%
  filter(continent == "Europe", year %in% c(1952, 1967))
ggplot(data = eu_5267, aes(x = gdpPercap, y = lifeExp, 
                           color = factor(year))) +
  geom_point()                                          
```

## Ex 2 done?

commit

##

**Ex REDO: Your collaborator realized that the data set they sent you 
was wrong. Repeat Exercises 1 and 2 with the updated dataset.**

```{r}
gap_upd <- read.csv(curl("http://bit.ly/gap_data_upd"))
```

## REDO done?

commit, and push, we're done with exercises for the day

## Organizing a more complex analysis

- Use folders: raw_data, processed_data, code, figures, etc.

- Number your script files:
    + `00_load_data.R`
    + `01_data_cleanup.R`
    + `02_eda.R`
    + ...

- Use informative names that indicate versioning
    + use dates
    + avoid things like `project_fin`, `project_finalfinal`, etc.

# Using more than one machine

## Really big jobs

What do you do when one machine is not enough? (Meaning everything is
optimized and things still take forever)

<br/>

- We will cover what to do if things can be parallelized

<br/>

- If they can't - learn to be patient


## Long running jobs

Some of you may have noticed if you launch a long running process on a 
remote machine (or locally)

- If the connection closes your job dies

- Can be prevented by prefixing your command with `nohup`

<div class="centered">
`nohup Rscript long_analysis.R`
</div>

<br style="margin:10px" />

- Can check on status using `ps` or `top` but no way to directly interact with process

    + Good idea to pipe output to a file

    + Terminate using PID and `kill`

    + If you really want interactivity use `screen`


## Being a good citizen

- You are not the only user on a system - many of the departments systems 
also serve as desktops.

- Disrupt other users as little as possible

- Don't use all the CPU or all the memory

- Long running / multi-CPU jobs should use `nice`

    + Lowers (or raises) the priority of your task

    + Prefix command, positive values indicate lower priority

<div class="centered">
`nice +19 Rscript long_analysis.R`
</div>

## Simple / small parallelism?

If you have a simple situation (e.g. run three model variants)

<br/>

Launch things manually 

- ssh to several servers

- Run the command with `nohup` and `nice`

- Pipe output to a file

- Periodically check on progress

<br/>

This type of thing is easily scriptable via the shell or R for more 
complex jobs


## Lots of parallelism?

Use HTCondor - a distributed job management system that scavenges 
resources from systems in the department and/or university.

- Used by Stats, and Physics, and OIT, and ...

- Easiest access to the largest pool of CPUs without having to deal 
with Duke's cluster

- Has limitations - not ideal for long running jobs in R

- Recently setup in the department, documentation and tools are still 
forthcoming

# Acknowledgements

## Acknowledgements

- Some of the materials are result of the NSF supported [Reproducible Science Curriculum Hackathon](https://github.com/Reproducible-Science-Curriculum/Reproducible-Science-Hackathon-Dec-08-2014) that was held December 8-11, 2014, at the National Evolutionary Synthesis Center ([NESCent](http://nescent.org/)) in Durham, NC.

- [GitHub's ssh help pages](https://help.github.com/categories/56/articles)

- [Software Carpentry Project](http://software-carpentry.org/)

- Karl Broman - [Wisc's Tools4RR](http://kbroman.org/Tools4RR/)

- Karl Broman - [Reproducible Research](https://www.biostat.wisc.edu/~kbroman/presentations/repro_research_withnotes.pdf)

- [An Introduction to Using HTCondor](http://research.cs.wisc.edu/htcondor/HTCondorWeek2014/presentations/MillerK_IntroTutorial.pdf)